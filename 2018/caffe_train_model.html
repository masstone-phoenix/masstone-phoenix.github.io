<!DOCTYPE HTML>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <meta name="Keywords" content="blog"/>
    <meta name="Description" content="blog"/>
    <title>Simple</title>
    <link rel="shortcut icon" href="/static/favicon.png"/>
    <link rel="stylesheet" type="text/css" href="/main.css" />
</head>
<body>
<div class="main">
    <div class="header">
    	<ul id="pages">
            <li><a href="/">home</a></li>
            <li><a href="/#/tags">tags</a></li>
            <li><a href="/#/archive">archive</a></li>
    	</ul>
    </div>
	<div class="wrap-header">
	<h1>
    <a href="/" id="title"></a>
	</h1>
	</div>
<div id="md" style="display: none;">
<!-- markdown -->
由于需要使用caffe自己训练一个模型，学习了其组成等，这里总结一下，主要参考[这里](http://caffe.berkeleyvision.org/tutorial/)和[这里](https://docs.google.com/presentation/d/1UeKXVgRvvxg9OUdh_UiC5G71UMscNPlvArsWER41PsU/edit#slide=id.gc2fcdcce7_216_264)。

# 基本哲学
在开始时，它就介绍了自己遵守的哲学，其中使用**文本来表达模型**和**模块化**比较让人印象深刻；开放，社区是这个框架的特点。这些在后面的使用时，都会对框架的理解比较有帮助。

# 基本概念
机器学习的模型是一般是一个神经网络，而一个神经网络是是由一层一层的神经元组成的，数据从输入层沿着神经网络流动到输出层，从而得到输出数据。Caffe将一层的神经元抽象为Layer，将整个网络抽象为Net，而沿着神经网络流动的数据抽象为Blob。

## Blob
上面提到了，Blob是对数据的抽象，同时，它还隐藏了数据从CPU和GPU之间同步的细节。在数学上，一个blob是一个C语言中连接存储的N维数组，数组按行依次存放其中的各元素,即以行为主的顺序分配，比如在一个4D blob中，索引 (n, k, h, w) 处的元素的内存位置是 ((n * K + k) * H + h) * W + w。

当然，Blob还可以表示参数等数据。

在使用时，如果不需要改动数据，尽量使用const函数，这样可以避免CPU和GPU之间拷贝数据，提高性能。

## Layer

### Layer Protocol
- Setup: 初始化自身以及其网络连接，只运行一次。
- Forward: 计算输出结果。
- Backward: 计算参数的导数值。
- Reshape: 设置dims。

## Net
用来管理所有Layer和Blob的类，是整个模型的抽象。

# 自己搭建一个模型

## 定义模型的checklist
1. Convert the data to Caffe-format:lmdb, leveldb, hdf5 / .mat, list of images, etc.
2. Define the Net
3. Configure the Solver
4. caffe train -solver solver.prototxt -gpu 0

以下就按上述步骤来自己定义一个模型：

## 将数据转化成caffe支持的格式
这里使用lmdb做为例子，输入是你自己的图片目录（需要有特定模式）转换成一个lmdb库文件输出;这个过程一般由caffe工具convert_imageset完成，该工具在编译过的caffe-master/build/tools目录下。

上述提到的模式是指，在目录下有两个标签文件train.txt，val.txt，这两个文件用来表示图片对应的标签分类，其内容结构如下：

```
T10034.jpg 1
221169_02M52.JPG 0
T580.jpg 1
T4694.jpg 1
332136_01M17.JPG 0
181085_02M28.JPG 0
133417_02M37.JPG 0
```

这个文件可以通过修改下面的脚本来进行生成，也可以自己写一个脚本来生成。

```
//https://www.ctolib.com/topics-101665.html
# /usr/bin/env sh
DATA=examples/images
echo "Create train.txt..."
rm -rf $DATA/train.txt
find $DATA -name *cat.jpg | cut -d '/' -f3 | sed "s/$/ 1/">>$DATA/train.txt
find $DATA -name *bike.jpg | cut -d '/' -f3 | sed "s/$/ 2/">>$DATA/tmp.txt
cat $DATA/tmp.txt>>$DATA/train.txt
rm -rf $DATA/tmp.txt
echo "Done.."
```

我这里使用python读取json文件来生成train.txt：
```
import json
from pprint import pprint

jsonFileName = 'face_boy.json'
picturesDirName = 'boy_2000_20180521'

with open(jsonFileName) as f:
    data = json.load(f)

pprint(data)

with open("train.txt", "w") as text_file:
    for key, value in data.items():
#         print("{} {}".format(key, value) )
        print("{} {}".format(key, value), file=text_file)
```

有了上述文件后，就可以使用convert_imageset工具来生成lmdb文件了。

```
convert_imageset [FLAGS] ROOTFOLDER/ LISTFILE DB_NAME
```

其中四个参数含义如下：

- FLAGS: 图片参数组
	- gray: 是否以灰度图的方式打开图片。程序调用opencv库中的imread()函数来打开图片，默认为false。
	- shuffle: 是否随机打乱图片顺序。默认为false。
	- backend:需要转换成的db文件格式，可选为leveldb或lmdb,默认为lmd。
	- resize_width/resize_height: 改变图片的大小。在运行中，要求所有图片的尺寸一致，因此需要改变图片大小。 程序调用opencv库的resize（）函数来对图片放大缩小，默认为0，不改变。
	- check_size: 检查所有的数据是否有相同的尺寸。默认为false,不检查。
	- encoded: 是否将原图片编码放入最终的数据中，默认为false。
	- encode_type: 与前一个参数对应，将图片编码为哪一个格式：‘png’,’jpg’等。
- ROOTFOLDER/: 图片存放的绝对路径，从linux系统根目录开始(不是caffe根目录，需要图片存放的绝对路径)
- LISTFILE: 图片文件列表清单，一般为一个txt文件，一行一张图片
- DB_NAME: 最终生成的db文件存放目录

我们可以使用一个文件记录下生成的命令，方便下次生成时使用：

```
DATA=examples/images
rm -rf $DATA/img_train_lmdb
build/tools/convert_imageset --shuffle --resize_height=256 --resize_width=256 /home/moqi/caffe/examples/images/ $DATA/train.txt  $DATA/img_train_lmdb
```

## 定义神经网络

Caffe定义模型使用如下的plain文本来定义，一个模型是由一个一个的层来定义的，如下：
```
layer: {
  name: 'innerproduct1'
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 10
    bias_term: false
    weight_filler {
      type: 'gaussian'
      std: 10
    }
  }
  param: 'sharedweights'
  bottom: 'data'
  top: 'innerproduct1'
}
layer: {
  name: 'innerproduct2'
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 10
    bias_term: false
  }
  param: 'sharedweights'
  bottom: 'data'
  top: 'innerproduct2'
}

```

每个layer都有一些固定的选项，上面两个层的param参数的名字都是sharedweights，它们的参数是共享的（也就是Weight Sharing）。

<!-- markdown end -->
</div>
<div class="entry" id="main">
<!-- content -->
<p>由于需要使用caffe自己训练一个模型，学习了其组成等，这里总结一下，主要参考<a href="http://caffe.berkeleyvision.org/tutorial/">这里</a>和<a href="https://docs.google.com/presentation/d/1UeKXVgRvvxg9OUdh_UiC5G71UMscNPlvArsWER41PsU/edit#slide=id.gc2fcdcce7_216_264">这里</a>。</p>

<h1 id="">基本哲学</h1>

<p>在开始时，它就介绍了自己遵守的哲学，其中使用<strong>文本来表达模型</strong>和<strong>模块化</strong>比较让人印象深刻；开放，社区是这个框架的特点。这些在后面的使用时，都会对框架的理解比较有帮助。</p>

<h1 id="">基本概念</h1>

<p>机器学习的模型是一般是一个神经网络，而一个神经网络是是由一层一层的神经元组成的，数据从输入层沿着神经网络流动到输出层，从而得到输出数据。Caffe将一层的神经元抽象为Layer，将整个网络抽象为Net，而沿着神经网络流动的数据抽象为Blob。</p>

<h2 id="blob">Blob</h2>

<p>上面提到了，Blob是对数据的抽象，同时，它还隐藏了数据从CPU和GPU之间同步的细节。在数学上，一个blob是一个C语言中连接存储的N维数组，数组按行依次存放其中的各元素,即以行为主的顺序分配，比如在一个4D blob中，索引 (n, k, h, w) 处的元素的内存位置是 ((n * K + k) * H + h) * W + w。</p>

<p>当然，Blob还可以表示参数等数据。</p>

<p>在使用时，如果不需要改动数据，尽量使用const函数，这样可以避免CPU和GPU之间拷贝数据，提高性能。</p>

<h2 id="layer">Layer</h2>

<h3 id="layerprotocol">Layer Protocol</h3>

<ul>
<li>Setup: 初始化自身以及其网络连接，只运行一次。</li>
<li>Forward: 计算输出结果。</li>
<li>Backward: 计算参数的导数值。</li>
<li>Reshape: 设置dims。</li>
</ul>

<h2 id="net">Net</h2>

<p>用来管理所有Layer和Blob的类，是整个模型的抽象。</p>

<h1 id="">自己搭建一个模型</h1>

<h2 id="checklist">定义模型的checklist</h2>

<ol>
<li>Convert the data to Caffe-format:lmdb, leveldb, hdf5 / .mat, list of images, etc.</li>
<li>Define the Net</li>
<li>Configure the Solver</li>
<li>caffe train -solver solver.prototxt -gpu 0</li>
</ol>

<p>以下就按上述步骤来自己定义一个模型：</p>

<h2 id="caffe">将数据转化成caffe支持的格式</h2>

<p>这里使用lmdb做为例子，输入是你自己的图片目录（需要有特定模式）转换成一个lmdb库文件输出;这个过程一般由caffe工具convert_imageset完成，该工具在编译过的caffe-master/build/tools目录下。</p>

<p>上述提到的模式是指，在目录下有两个标签文件train.txt，val.txt，这两个文件用来表示图片对应的标签分类，其内容结构如下：</p>

<pre><code>T10034.jpg 1
221169_02M52.JPG 0
T580.jpg 1
T4694.jpg 1
332136_01M17.JPG 0
181085_02M28.JPG 0
133417_02M37.JPG 0
</code></pre>

<p>这个文件可以通过修改下面的脚本来进行生成，也可以自己写一个脚本来生成。</p>

<pre><code>//https://www.ctolib.com/topics-101665.html
# /usr/bin/env sh
DATA=examples/images
echo "Create train.txt..."
rm -rf $DATA/train.txt
find $DATA -name *cat.jpg | cut -d '/' -f3 | sed "s/$/ 1/"&gt;&gt;$DATA/train.txt
find $DATA -name *bike.jpg | cut -d '/' -f3 | sed "s/$/ 2/"&gt;&gt;$DATA/tmp.txt
cat $DATA/tmp.txt&gt;&gt;$DATA/train.txt
rm -rf $DATA/tmp.txt
echo "Done.."
</code></pre>

<p>我这里使用python读取json文件来生成train.txt：</p>

<pre><code>import json
from pprint import pprint

jsonFileName = 'face_boy.json'
picturesDirName = 'boy_2000_20180521'

with open(jsonFileName) as f:
    data = json.load(f)

pprint(data)

with open("train.txt", "w") as text_file:
    for key, value in data.items():
#         print("{} {}".format(key, value) )
        print("{} {}".format(key, value), file=text_file)
</code></pre>

<p>有了上述文件后，就可以使用convert_imageset工具来生成lmdb文件了。</p>

<pre><code>convert_imageset [FLAGS] ROOTFOLDER/ LISTFILE DB_NAME
</code></pre>

<p>其中四个参数含义如下：</p>

<ul>
<li>FLAGS: 图片参数组
<ul><li>gray: 是否以灰度图的方式打开图片。程序调用opencv库中的imread()函数来打开图片，默认为false。</li>
<li>shuffle: 是否随机打乱图片顺序。默认为false。</li>
<li>backend:需要转换成的db文件格式，可选为leveldb或lmdb,默认为lmd。</li>
<li>resize<em>width/resize</em>height: 改变图片的大小。在运行中，要求所有图片的尺寸一致，因此需要改变图片大小。 程序调用opencv库的resize（）函数来对图片放大缩小，默认为0，不改变。</li>
<li>check<em>size: 检查所有的数据是否有相同的尺寸。默认为false,不检查。</em></li><em>
<li>encoded: 是否将原图片编码放入最终的数据中，默认为false。</li>
</em><li><em>encode</em>type: 与前一个参数对应，将图片编码为哪一个格式：‘png’,’jpg’等。</li></ul></li>
<li>ROOTFOLDER/: 图片存放的绝对路径，从linux系统根目录开始(不是caffe根目录，需要图片存放的绝对路径)</li>
<li>LISTFILE: 图片文件列表清单，一般为一个txt文件，一行一张图片</li>
<li>DB_NAME: 最终生成的db文件存放目录</li>
</ul>

<p>我们可以使用一个文件记录下生成的命令，方便下次生成时使用：</p>

<pre><code>DATA=examples/images
rm -rf $DATA/img_train_lmdb
build/tools/convert_imageset --shuffle --resize_height=256 --resize_width=256 /home/moqi/caffe/examples/images/ $DATA/train.txt  $DATA/img_train_lmdb
</code></pre>

<h2 id="">定义神经网络</h2>

<p>Caffe定义模型使用如下的plain文本来定义，一个模型是由一个一个的层来定义的，如下：</p>

<pre><code>layer: {
  name: 'innerproduct1'
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 10
    bias_term: false
    weight_filler {
      type: 'gaussian'
      std: 10
    }
  }
  param: 'sharedweights'
  bottom: 'data'
  top: 'innerproduct1'
}
layer: {
  name: 'innerproduct2'
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 10
    bias_term: false
  }
  param: 'sharedweights'
  bottom: 'data'
  top: 'innerproduct2'
}
</code></pre>

<p>每个layer都有一些固定的选项，上面两个层的param参数的名字都是sharedweights，它们的参数是共享的（也就是Weight Sharing）。</p>
<!-- content end -->
</div>
<br>
<br>
    <div id="disqus_thread"></div>
	<div class="footer">
		<p>© Copyright 2014 by isnowfy, Designed by isnowfy</p>
	</div>
</div>
<script src="main.js"></script>
<script id="content" type="text/mustache">
    <h1>{{title}}</h1>
    <div class="tag">
    {{date}}
    {{#tags}}
    <a href="/#/tag/{{name}}">#{{name}}</a>
    {{/tags}}
    </div>
</script>
<script id="pagesTemplate" type="text/mustache">
    {{#pages}}
    <li>
        <a href="{{path}}">{{title}}</a>
    </li>
    {{/pages}}
</script>
<script>
$(document).ready(function() {
    $.ajax({
        url: "main.json",
        type: "GET",
        dataType: "json",
        success: function(data) {
            $("#title").html(data.name);
            var pagesTemplate = Hogan.compile($("#pagesTemplate").html());
            var pagesHtml = pagesTemplate.render({"pages": data.pages});
            $("#pages").append(pagesHtml);
            //path
            var path = "2018/caffe_train_model.html";
            //path end
            var now = 0;
            for (var i = 0; i < data.posts.length; ++i)
                if (path == data.posts[i].path)
                    now = i;
            var post = data.posts[now];
            var tmp = post.tags.split(" ");
            var tags = [];
            for (var i = 0; i < tmp.length; ++i)
                if (tmp[i].length > 0)
                    tags.push({"name": tmp[i]});
            var contentTemplate = Hogan.compile($("#content").html());
            var contentHtml = contentTemplate.render({"title": post.title, "tags": tags, "date": post.date});
            $("#main").prepend(contentHtml);
            if (data.disqus_shortname.length > 0) {
                var disqus_shortname = data.disqus_shortname;
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            }
        }
    });
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ["\\(", "\\)"]], processEscapes: true}});
</script>
</body>
</html>
